{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means\n",
    "**time : 2019/12/25**   \n",
    "**author: mjl**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.算法原理\n",
    "k-means是最普及的聚类算法，算法接受一个来标记的数据集，然后将数据聚类成不同的组。  \n",
    "\n",
    "使用$\\mu^{1},\\mu^{2},\\mu^{3},...,\\mu^{k}$来表示聚类中心，用$c^{1},c^{2},c^{3},...,c^{m}$来存储与第i个实例数据最近的聚类中心的索引。  \n",
    "\n",
    "k-means的优化目标，其实是最小化所有数据点与其所关联的聚类中心点之间的距离之和。即k-means的代价函数：  \n",
    "\n",
    "$J(c^{1},c^{2},c^{3},...,c^{m}, \\mu^{1},\\mu^{2},\\mu^{3},...,\\mu^{k}) = \\frac{1}{m}\\sum \\left \\| x^{i} - \\mu^{c_{i}} \\right \\|^{2}$  \n",
    "\n",
    "其中$\\mu^{i}$代表与$x_{i}$最近的聚类中心点，我们的优化目标便是找出使得代价函数最小的$c^{1},c^{2},c^{3},...,c^{m}$和$\\mu^{1},\\mu^{2},\\mu^{3},...,\\mu^{k}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.算法实现\n",
    "k-means是最普及的聚类算法，算法接受一个来标记的数据集，然后将数据聚类成不同的组。算法分为两个步骤，第一个for循环是赋值步骤，即对于每一个样例i，计算其应该属于的类。第二个for循环是聚类中心的移动，即对于每一个类k，重新计算该类的中心。  \n",
    "Repeat {  \n",
    "&emsp;&emsp;  for i = 1 : m      \n",
    "&emsp;&emsp;&emsp;&emsp; $C^{i}$ = index (from 1 to k) of cluster centroid  \n",
    "      \n",
    "&emsp;&emsp;  for k = 1 : K  \n",
    "&emsp;&emsp;&emsp;&emsp; $\\mu^{k}$ = average (mean) of points assigned to cluster k  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuary(targets, labels):\n",
    "    return np.mean(targets == labels, axis=0)\n",
    "\n",
    "def distance(x1, x2):\n",
    "    return np.power(np.sum(np.power(x1 - x2, 2)), 0.5)\n",
    "\n",
    "def kmeans(data, labels, classs = 12, epoch=100):\n",
    "    ## 记录每个数据的中心\n",
    "    pos = [i for i in range(0, len(labels))]\n",
    "    ## 聚类中心， 初始时进行随机初始化\n",
    "    center = []\n",
    "    for i in random.sample(range(0, len(labels)), classs):\n",
    "        center.append(data[i, :])\n",
    "    center = np.array(center)\n",
    "    \n",
    "    for m in range(epoch):\n",
    "        for i, x1 in enumerate(data):\n",
    "            diss = []\n",
    "            ## 计算每个点到所有中心的距离\n",
    "            for x2 in center:\n",
    "                diss.append(distance(x1, x2))\n",
    "            ## 将数据聚类到距离其最小的中心\n",
    "            pos[i] = np.argmin(diss)\n",
    "        ## 下面是通过前面聚类到的数据， 对中心进行更新\n",
    "        for i in range(classs):\n",
    "            center[i] = 0\n",
    "        for i, x in enumerate(data):\n",
    "            center[pos[i]] += x\n",
    "        ## 这里， 中心的更新， 就是对属于其的数据的坐标进行平均\n",
    "        for i in range(classs):\n",
    "            center[i] = center[i] / np.sum(np.array(pos) == i)\n",
    "    return center\n",
    "\n",
    "def predict(x, y, classs, center):\n",
    "    pos = [i for i in range(0, x.shape[0])]\n",
    "    for i, x1 in enumerate(x):\n",
    "        diss = []\n",
    "        for x2 in center:\n",
    "            diss.append(distance(x1, x2))\n",
    "        pos[i] = np.argmin(diss)\n",
    "    print(accuary(np.array(pos).reshape([-1, 1]), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X1 = scaler.fit_transform(load_breast_cancer()['data'])\n",
    "Y1 = load_breast_cancer()['target'].reshape([-1, 1])\n",
    "print(X1.shape)\n",
    "print(Y1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09841828]\n",
      "官方提供：\n",
      "[ 0.02636204]\n"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X1, Y1, test_size=.2)\n",
    "center = kmeans(X1, Y1, 12, 200)\n",
    "predict(X1, Y1, 12, center)\n",
    "\n",
    "print(\"官方提供：\")\n",
    "kmeans = KMeans(n_clusters=12)\n",
    "kmeans.fit(X1)\n",
    "pre = kmeans.predict(X1)\n",
    "print(accuary(pre.reshape([-1,1]), Y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
